{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will use the original data and the privatized data we just created to train models and compare their performance in terms of accuracy. We'll be demonstrating what is commonly referred in the literature as the privacy/utility tradeoff: We usually have to sacrifice some of the accuracy in the models, in exchange better preserving privacy. The epsilon value is usually the knob that is used to manage this trade-off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get location of data and vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first step will be to get the locations of the privatized dataset we created in the data privatization notebook, along with the pre-trained vector embeddings we'll be using. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from botocore.config import Config as BotocoreConfig\n",
    "from package import config\n",
    "import boto3\n",
    "\n",
    "# We create a SageMaker session and get the IAM role we'll be using\n",
    "sm_boto = boto3.client('sagemaker', config=BotocoreConfig(connect_timeout=5, read_timeout=60, retries={'max_attempts': 30}))\n",
    "sagemaker_session = sagemaker.Session(sagemaker_client = sm_boto)\n",
    "role = config.PRIVACY_SAGEMAKER_IAM_ROLE\n",
    "\n",
    "# Note the input and output buckets\n",
    "solution_bucket = f\"{config.SOLUTIONS_S3_BUCKET}-{config.AWS_REGION}\"\n",
    "bucket = config.S3_BUCKET\n",
    "solution_prefix = config.SOLUTION_NAME\n",
    "prefix = solution_prefix\n",
    "\n",
    "# These are the embeddings that we'll use for the model, same as with the privatization step.\n",
    "s3_vectors = \"s3://{}/{}/vectors/glove.6B.300d.txt.gz\".format(solution_bucket, solution_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the pre-processing notebook we created two training files, one with the original data, and one with the privatized version of the same reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "privatized_train_data = 's3://{}/{}/processed-data/reviews-privatized'.format(bucket, prefix)\n",
    "sensitive_train_data = \"s3://{}/{}/processed-data/reviews-sensitive\".format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training entry point is the `train.py` file under `./src/package/model/`. There we have included a `requirements.txt` file, Amazon SageMaker will use that to prepare the container for our training instances with all the required libraries.\n",
    "\n",
    "Since we are interested in training one model on the original data and one on the privatized data, our training script supports both, we only change the input dataset for each estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an estimator for the original data.\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "sensitive_train_output = 's3://{}/{}/sensitive-output'.format(bucket, prefix)\n",
    "sensitive_estimator = PyTorch(entry_point='train.py',\n",
    "                    source_dir='./src/package/model/',\n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    role=role,\n",
    "                    framework_version='1.5.0',\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type=config.TRAINING_INSTANCE_TYPE,\n",
    "                    base_job_name=f\"{config.SOLUTION_NAME}\",\n",
    "                    output_path=sensitive_train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an estimator for the privatized data.\n",
    "privatized_train_output = 's3://{}/{}/privatized-output'.format(bucket, prefix)\n",
    "privatized_estimator = PyTorch(entry_point='train.py',\n",
    "                    source_dir='./src/package/model/',\n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    role=role,\n",
    "                    framework_version='1.5.0',\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type=config.TRAINING_INSTANCE_TYPE,\n",
    "                    base_job_name=f\"{config.SOLUTION_NAME}\",\n",
    "                    output_path=privatized_train_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker gives us the option to launch one training job in the background, and continue working, using asynchronous training. We will make use of this capability here to launch the original data training job, and immediately after launch the privatized training data job. This allows the two training jobs to run in parallel, so we don't have to wait for them to finish in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sensitive_estimator.fit({\"train\": sensitive_train_data, \"vectors\": s3_vectors}, wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "privatized_estimator.fit({\"train\": privatized_train_data, \"vectors\": s3_vectors}, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we have started both training jobs and they working in the background. Next, we'll attach to those jobs, to get the estimators' output and wait until both are finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "privatized_estimator = PyTorch.attach(training_job_name=privatized_estimator.latest_training_job.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitive_estimator = PyTorch.attach(training_job_name=sensitive_estimator.latest_training_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Accuracy evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we we have both models trained, we can evaluate their performance on a test set to see how the perturbation has affected the model's accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we only want to evaluate the two different models on an existing test dataset, we can use an Amazon SageMaker Processing job to make predictions for all our test data and output the accuracy. We will use the same Docker container we used for our privatization job to run our predictions, but this time we're making use of GPU P3 instances to speed up model inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "\n",
    "ecr_repository = config.SAGEMAKER_PROCESSING_JOB_CONTAINER_NAME\n",
    "ecr_repository_uri = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account_id, config.AWS_REGION, ecr_repository)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the previous notebook, we set up a script processor, only switching over to a P3 instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "\n",
    "script_processor = ScriptProcessor(command=['python3'],\n",
    "                                   sagemaker_session=sagemaker_session,\n",
    "                                   image_uri=ecr_repository_uri,\n",
    "                                   role=role,\n",
    "                                   instance_count=1,\n",
    "                                   instance_type=config.PROCESSING_INSTANCE_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with our training job, we can start both jobs aync and let them run in parallel. We change the source and destination locations to match the model trained on sensitive and privatized data respectively, and run the jobs, giving them a job name that we can refer to later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "test_data = \"s3://{}/{}/data\".format(solution_bucket, solution_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitive_model_evaluation = 's3://{}/{}/sensitive-model-evaluation'.format(bucket, prefix)\n",
    "sensitive_job_name = \"sensitive-model-evaluation-{}\".format(int(time.time()))\n",
    "\n",
    "script_processor.run(code='src/package/model/inference.py',\n",
    "                     inputs=[ProcessingInput(source=test_data,\n",
    "                                             destination='/opt/ml/processing/data'),\n",
    "                            ProcessingInput(source=sensitive_estimator.model_data,\n",
    "                                             destination='/opt/ml/processing/model')],\n",
    "                     outputs=[ProcessingOutput(destination=sensitive_model_evaluation,\n",
    "                                               source='/opt/ml/processing/output')],\n",
    "                     job_name=sensitive_job_name,\n",
    "                     wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "privatized_model_evaluation = 's3://{}/{}/privatized-model-evaluation'.format(bucket, prefix)\n",
    "privatized_job_name = \"privatized-model-evaluation-{}\".format(int(time.time()))\n",
    "\n",
    "script_processor.run(code='src/package/model/inference.py',\n",
    "                     inputs=[ProcessingInput(source=test_data,\n",
    "                                             destination='/opt/ml/processing/data'),\n",
    "                            ProcessingInput(source=privatized_estimator.model_data,\n",
    "                                             destination='/opt/ml/processing/model')],\n",
    "                     outputs=[ProcessingOutput(destination=privatized_model_evaluation,\n",
    "                                               source='/opt/ml/processing/output')],\n",
    "                     job_name=privatized_job_name,\n",
    "                     wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can now wait until the jobs are finished. When the evaluation of the model trained on the original data is finished, the one trained on privatized should be done soon after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingJob\n",
    "\n",
    "sensitive_job = ProcessingJob.from_processing_name(\n",
    "    sagemaker_session, processing_job_name=sensitive_job_name)\n",
    "sensitive_job.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "privatized_job = ProcessingJob.from_processing_name(\n",
    "    sagemaker_session, processing_job_name=privatized_job_name)\n",
    "privatized_job.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Downloader\n",
    "from pathlib import Path\n",
    "\n",
    "Path('./sensitive-model-evaluation').mkdir(exist_ok=True)\n",
    "S3Downloader.download(sensitive_model_evaluation, \"./sensitive-model-evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy on original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ./sensitive-model-evaluation/accuracy-metrics.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "# Sensitive Data - ROC Curve\n",
    "Image(url= \"./sensitive-model-evaluation/accuracy-ROC.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy on privatized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path('./privatized-model-evaluation').mkdir(exist_ok=True)\n",
    "S3Downloader.download(privatized_model_evaluation, \"./privatized-model-evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ./privatized-model-evaluation/accuracy-metrics.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Privatized Data - ROC Curve\n",
    "Image(url= \"./privatized-model-evaluation/accuracy-ROC.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the exact numbers for accuracy might vary slightly between the two models, we should see that their performance is very similar.\n",
    "\n",
    "So even though as we saw in the pre-processing examples we have modified the exact words in the reviews quite heavily, thereby making it harder to identify individuals as the ones who wrote them, we lost very little in terms of the accuracy of the privatized model compared to the one trained on the original data.\n",
    "\n",
    "Using the proposed algorithm, customers can provide better privacy for their users, while maintaining accurate models that help meet their business needs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (PyTorch JumpStart) (sagemaker-jumpstart-pytorch/latest)",
   "language": "python",
   "name": "HUB_1P_IMAGE"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}